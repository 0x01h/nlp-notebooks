{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Simple Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings have become widespread in Natural Language Processing. They allow us to easily compute the semantic similarity between two words, or to find the words most similar to a target word. However, in many applications we're more interested in the similarity between two sentences or short texts. In this notebook, I compare some simple ways of computing sentence similarity and investigate how they perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STS Benchmark\n",
    "\n",
    "The STS Benchmark brings together the English data from the SemEval sentence similarity tasks between 2012 and 2017. The data is split in training, development and test data: http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_sts_dataset(filename):\n",
    "    # Loads a subset of the STS dataset into a DataFrame. In particular both\n",
    "    # sentences and their human rated similarity score.\n",
    "    sent_pairs = []\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            ts = line.strip().split(\"\\t\")\n",
    "            sent_pairs.append((ts[5], ts[6], float(ts[4])))\n",
    "    return pd.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n",
    "\n",
    "\n",
    "def download_and_load_sts_data():\n",
    "    sts_dataset = tf.keras.utils.get_file(\n",
    "        fname=\"Stsbenchmark.tar.gz\",\n",
    "        origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
    "        extract=True)\n",
    "\n",
    "    sts_dev = load_sts_dataset(os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"))\n",
    "    sts_test = load_sts_dataset(os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"))\n",
    "\n",
    "    return sts_dev, sts_test\n",
    "\n",
    "sts_dev, sts_test = download_and_load_sts_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A girl is styling her hair.</td>\n",
       "      <td>A girl is brushing her hair.</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A group of men play soccer on the beach.</td>\n",
       "      <td>A group of boys are playing soccer on the beach.</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One woman is measuring another woman's ankle.</td>\n",
       "      <td>A woman measures another woman's ankle.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man is cutting up a cucumber.</td>\n",
       "      <td>A man is slicing a cucumber.</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing a harp.</td>\n",
       "      <td>A man is playing a keyboard.</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sent_1  \\\n",
       "0                    A girl is styling her hair.   \n",
       "1       A group of men play soccer on the beach.   \n",
       "2  One woman is measuring another woman's ankle.   \n",
       "3                A man is cutting up a cucumber.   \n",
       "4                       A man is playing a harp.   \n",
       "\n",
       "                                             sent_2  sim  \n",
       "0                      A girl is brushing her hair.  2.5  \n",
       "1  A group of boys are playing soccer on the beach.  3.6  \n",
       "2           A woman measures another woman's ankle.  5.0  \n",
       "3                      A man is slicing a cucumber.  4.2  \n",
       "4                      A man is playing a keyboard.  1.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SICK data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_sick(f): \n",
    "\n",
    "    response = requests.get(f).text\n",
    "\n",
    "    lines = response.split(\"\\n\")[1:]\n",
    "    lines = [l.split(\"\\t\") for l in lines if len(l) > 0]\n",
    "    lines = [l for l in lines if len(l) == 5]\n",
    "\n",
    "    df = pd.DataFrame(lines, columns=[\"idx\", \"sent_1\", \"sent_2\", \"sim\", \"label\"])\n",
    "    df['sim'] = pd.to_numeric(df['sim'])\n",
    "    return df\n",
    "    \n",
    "sick_train = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_train.txt\")\n",
    "sick_dev = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_trial.txt\")\n",
    "sick_test = download_sick(\"https://raw.githubusercontent.com/alvations/stasis/master/SICK-data/SICK_test_annotated.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "      <th>sim</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx                                             sent_1  \\\n",
       "0   1  A group of kids is playing in a yard and an ol...   \n",
       "1   2  A group of children is playing in the house an...   \n",
       "2   3  The young boys are playing outdoors and the ma...   \n",
       "3   5  The kids are playing outdoors near a man with ...   \n",
       "4   9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                              sent_2  sim       label  \n",
       "0  A group of boys in a yard is playing and a man...  4.5     NEUTRAL  \n",
       "1  A group of kids is playing in a yard and an ol...  3.2     NEUTRAL  \n",
       "2  The kids are playing outdoors near a man with ...  4.7  ENTAILMENT  \n",
       "3  A group of kids is playing in a yard and an ol...  3.4     NEUTRAL  \n",
       "4  A group of kids is playing in a yard and an ol...  3.7     NEUTRAL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sick_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "class Sentence:\n",
    "    \n",
    "    def __init__(self, sentence):\n",
    "        self.raw = sentence\n",
    "        normalized_sentence = sentence.lower().replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "        self.tokens = [t for t in nltk.word_tokenize(sentence) if t not in STOP]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "As our baseline, we're going for the simplest way of computing sentence embeddings: just take the embeddings of the words in the sentence (minus the stopwords), and compute their average, weighted by the sentence frequency of each word. \n",
    "\n",
    "We'll then use the cosine to calculate the similarity between two sentence embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def sum_embeddings(tokens, model):\n",
    "    return sum([model[token] for token in tokens if token in model])/len(tokens)\n",
    "\n",
    "def cosine1(tokens1, tokens2, model): \n",
    "    embedding1 = sum_embeddings(tokens1, model).reshape(1, -1)\n",
    "    embedding2 = sum_embeddings(tokens2, model).reshape(1, -1)\n",
    "    \n",
    "    return cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "def run_avg_benchmark_word2vec(sentences1, sentences2): \n",
    "    return [cosine1(sent1.tokens, sent2.tokens, gensim_model_word2vec)[0][0] for (sent1, sent2) in zip(sentences1, sentences2)]\n",
    "\n",
    "def run_avg_benchmark_glove(sentences1, sentences2): \n",
    "    return [cosine1(sent1.tokens, sent2.tokens, gensim_model_glove)[0][0] for (sent1, sent2) in zip(sentences1, sentences2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def run_spacy_benchmark(sentences1, sentences2): \n",
    "    return [nlp(sent1.raw).similarity(nlp(sent2.raw)) for (sent1, sent2) in zip(sentences1, sentences2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word mover's distance\n",
    "\n",
    "Word mover's distance is a popular alternative to the simple average embedding similarity. The Word Mover's Distance uses the word embeddings of the words in two texts to measure the minimum amount that the words in one text need to \"travel\" in semantic space to reach the words of the other text. Word mover's distance is available in the popular Gensim library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "word2vec_path = \"/Users/yvespeirsman/Corpora/WordVectors/GoogleNews-vectors-negative300.bin\"\n",
    "glove_path = \"/Users/yvespeirsman/Corpora/WordVectors/glove.840B.300d.txt\"\n",
    "\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format(\"/Users/yvespeirsman/data/fastText/fr/wiki_100000.fr.vec\")\n",
    "gensim_model_word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "tmp_file = \"/tmp/glove.840B.300d.w2v.txt\"\n",
    "glove2word2vec(glove_path, tmp_file)\n",
    "gensim_model_glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wmd_benchmark_word2vec(sentences1, sentences2):\n",
    "    return [-gensim_model_word2vec.wmdistance(sent1.tokens, sent2.tokens) for (sent1, sent2) in zip(sentences1, sentences2)]\n",
    "\n",
    "def run_wmd_benchmark_glove(sentences1, sentences2):\n",
    "    return [-gensim_model_glove.wmdistance(sent1.tokens, sent2.tokens) for (sent1, sent2) in zip(sentences1, sentences2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth Inverse Frequency\n",
    "\n",
    "Get word frequencies from reference corpus such as Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "with open(\"frequencies.tsv\") as i:\n",
    "    for line in i:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        frequencies[line[0]] = int(line[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute SIF sentence embeddings, we first compute a weighted average of the token embeddings in the sentence. This procedure is very similar to the weighted average we used above, with the single difference that the word embeddings are weighted by `a/a+p(w)`, where `w` is a parameter that is set to `0.001` by default, and `p(w)` is the estimated relative frequency of a word in a reference corpus such as Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_embeddings(tokens, freqs, a=0.001):\n",
    "    total_freq = sum(freqs.values())\n",
    "    \n",
    "    sentence_embedding = np.zeros(300)\n",
    "    for token in tokens:\n",
    "        if token in gensim_model:\n",
    "            weight = a/(a+freqs.get(token,0)/total_freq)\n",
    "            token_embedding = gensim_model[token]\n",
    "            sentence_embedding += weight * token_embedding\n",
    "    sentence_embedding /= len(tokens)\n",
    "    return sentence_embedding\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to perform common component removal: we compute the principal component of the sentence embeddings we obtained above and subtract from them their projections on this first principal component. This corrects for the influence of high-frequency words that mostly have a syntactic or discourse function, such as \"just\", \"there\", \"but\", etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def remove_first_principal_component(X):\n",
    "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n",
    "    svd.fit(X)\n",
    "    pc = svd.components_\n",
    "    XX = X - X.dot(pc.transpose()) * pc\n",
    "    return XX\n",
    "\n",
    "\n",
    "def run_sif_benchmark(sentences1, sentences2): \n",
    "    sentence_embeddings = []\n",
    "    \n",
    "    # SIF requires us to first collect all sentence embeddings and then perform \n",
    "    # common component analysis.\n",
    "    for (sent1, sent2) in zip(sentences1, sentences2): \n",
    "        embedding1 = weighted_average_embeddings(sent1.tokens, frequencies)\n",
    "        embedding2 = weighted_average_embeddings(sent2.tokens, frequencies)\n",
    "\n",
    "        sentence_embeddings.append(embedding1)\n",
    "        sentence_embeddings.append(embedding2)\n",
    "        \n",
    "    sif_sims = []\n",
    "    embeddings_for_sif = remove_first_principal_component(np.array(sentence_embeddings))\n",
    "    for idx in range(int(len(sentence_embeddings)/2)): \n",
    "        embedding1 = sentence_embeddings[idx*2].reshape(1, -1)\n",
    "        embedding2 = sentence_embeddings[idx*2+1].reshape(1, -1)\n",
    "        sim = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "        sif_sims.append(sim)\n",
    "\n",
    "    return sif_sims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gse_benchmark(sentences1, sentences2):\n",
    "    sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "    sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "    sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\n",
    "    sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\n",
    "        \n",
    "    sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "      \n",
    "        [gse_sims] = session.run(\n",
    "            [sim_scores],\n",
    "            feed_dict={\n",
    "                sts_input1: [sent1.raw for sent1 in sentences1],\n",
    "                sts_input2: [sent2.raw for sent2 in sentences2]\n",
    "            })\n",
    "    return gse_sims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InferSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/facebookresearch/SentEval/master/examples/models.py\n",
    "!wget https://s3.amazonaws.com/senteval/infersent/infersent.allnli.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'models.BLSTMEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "infersent = torch.load('infersent.allnli.pickle', map_location=lambda storage, loc: storage)\n",
    "infersent.use_cuda = False\n",
    "\n",
    "infersent.set_glove_path(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inf_benchmark(sentences1, sentences2):\n",
    "    \n",
    "    raw_sentences1 = [sent1.raw for sent1 in sentences1]\n",
    "    raw_sentences2 = [sent2.raw for sent2 in sentences2]\n",
    "    \n",
    "    infersent.build_vocab(raw_sentences1 + raw_sentences2, tokenize=True)\n",
    "    embeddings1 = infersent.encode(raw_sentences1, tokenize=True)\n",
    "    embeddings2 = infersent.encode(raw_sentences2, tokenize=True)\n",
    "    \n",
    "    inf_sims = []\n",
    "    for (emb1, emb2) in zip(embeddings1, embeddings2): \n",
    "        sim = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n",
    "        inf_sims.append(sim)\n",
    "\n",
    "    return inf_sims    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(df, benchmarks): \n",
    "    \n",
    "    sentences1 = [Sentence(s) for s in df['sent_1']]\n",
    "    sentences2 = [Sentence(s) for s in df['sent_2']]\n",
    "    \n",
    "    results = []\n",
    "    for label, method in benchmarks:\n",
    "        sims = method(sentences1, sentences2)\n",
    "        pearson_correlation = scipy.stats.pearsonr(sims, df['sim'])[0]\n",
    "        print(label, pearson_correlation)\n",
    "        results.append(pearson_correlation)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG-W2V 0.6807758500465102\n",
      "AVG-GLOVE 0.6489807517892621\n",
      "WMD-W2V 0.6084992388068139\n",
      "WMD-GLOVE 0.6109008925446218\n",
      "SPACY 0.639281159053343\n",
      "Running SIF benchmark\n",
      "SIF 0.6797767718965236\n",
      "Running GSE benchmark\n",
      "GSE 0.7282557455668891\n",
      "Running INF benchmark\n",
      "Found 1121(/1122) words with glove vectors\n",
      "Vocab size : 1121\n",
      "INF 0.7008594698958657\n",
      "AVG-W2V 0.7013252067023191\n",
      "AVG-GLOVE 0.6765999568968976\n",
      "WMD-W2V 0.6090334015900284\n",
      "WMD-GLOVE 0.604632708760861\n",
      "SPACY 0.6647556918342541\n",
      "Running SIF benchmark\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5a45cde81a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SICK-DEV\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msick_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SICK-TEST\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msick_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"STS-DEV\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msts_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"STS-TEST\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msts_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-0963be46453b>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(df, benchmarks)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpearson_correlation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpearson_correlation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-01207a705562>\u001b[0m in \u001b[0;36mrun_sif_benchmark\u001b[0;34m(sentences1, sentences2)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0membedding1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_average_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0membedding2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_average_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msentence_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8635fdc76f5c>\u001b[0m in \u001b[0;36mweighted_average_embeddings\u001b[0;34m(tokens, freqs, a)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweighted_average_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtotal_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msentence_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "benchmarks = [(\"AVG-W2V\", run_avg_benchmark_word2vec),\n",
    "              (\"AVG-GLOVE\", run_avg_benchmark_glove),\n",
    "              (\"WMD-W2V\", run_wmd_benchmark_word2vec), \n",
    "              (\"WMD-GLOVE\", run_wmd_benchmark_glove), \n",
    "              (\"SPACY\", run_spacy_benchmark), \n",
    "              (\"SIF\", run_sif_benchmark), \n",
    "              (\"GSE\", run_gse_benchmark), \n",
    "              (\"INF\", run_inf_benchmark)]\n",
    "\n",
    "results = {}\n",
    "results[\"SICK-DEV\"] = run_experiment(sick_dev, benchmarks)\n",
    "results[\"SICK-TEST\"] = run_experiment(sick_test, benchmarks)\n",
    "results[\"STS-DEV\"] = run_experiment(sts_dev, benchmarks)\n",
    "results[\"STS-TEST\"] = run_experiment(sts_test, benchmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x3023cbe48>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEkCAYAAADU2nGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3X18VNW97/HPL6HBBxDFBEWeEhEUEUSNCGoVtVU8WrBIJdhzlPYoVgUrchWoaLn22iO2VO2VWqO1clpJULzVlOJDqahVqAUpPgQO5aGhBCgFCtrgA0V+94+ZhJ1hQnbiTCaz+b5fr7zce62VPb+Me36sWWvvtc3dERGRaMnJdAAiIpJ6Su4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhGk5C4iEkFtMvXC+fn5XlhYmKmXFxHJSm+//fY2dy9orF3GknthYSFLly7N1MuLiGQlM1sfpp2GZUREIkjJXUQkgpTcRUQiSMldRCSClNxFRCJIyV1EJIKU3EVEIkjJXUQkgjJ2E5OIpM/Mb73SYN0nO37UYN3EOfPSEY5kgHruIiIRpOQuIhJBGpaRVkNDCSKpo567iEgEKbmLiESQkruISARpzP1zONAY8c0/vbAFIxERqU89dxGRCFLPXaQFFE7+TYN1Vfdd1qxjrjypT8OVQ2Y265gSHeq5i4hEUKieu5kNBR4CcoHH3f2+hPoHgAviu4cBndz9yFQGKiKSKdk4v9ZocjezXGAm8GWgGlhiZhXuvqK2jbtPCLQfD5yWhlhFRCSkMMMyA4E17r7O3XcD5cDwA7QfDZSlIjgREWmeMMMyXYANgf1q4KxkDc2sB1AEJP0OY2ZjgbEA3bt3b1Kg2WbGqMsbrMuW2+U1CSiSvcL03C1JmTfQtgSY6+6fJat091J3L3b34oKCgrAxiohIE4VJ7tVAt8B+V2BTA21L0JCMiEjGhUnuS4BeZlZkZnnEEnhFYiMzOxE4Clic2hBFRKSpGk3u7r4HGAe8BKwEnnb3SjO7x8yGBZqOBsrdvaEhGxERaSGhrnN39/nA/ISyuxP2p6UuLBER+TwitfyAru4QEYnR8gMiIhEUqZ67iEhLa633tKjnLiISQeq5S/NM63CAug9aLg4RSUo9dxGRCFJyFxGJICV3EZEIUnIXEYkgJXcRkQjS1TIirVi/Wf0arHu6BeOQ7HPwJHdduiciBxENy4iIRJCSu4hIBCm5i4hEkJK7iEgEHTwTqiISGel4dkPUKLmLiBC9B/NoWEZEJIJC9dzNbCjwEJALPO7u9yVpcxUwDXDgHXe/OoVxShbRjTcimddocjezXGAm8GWgGlhiZhXuviLQphcwBTjH3XeYWad0BZwOSkYiEjVhhmUGAmvcfZ277wbKgeEJba4HZrr7DgB3/3tqwxQRkaYIk9y7ABsC+9XxsqDeQG8ze9PM/hAfxtmPmY01s6VmtnTr1q3Ni1hERBoVJrlbkjJP2G8D9AKGAKOBx83syP1+yb3U3YvdvbigoKCpsYqISEhhkns10C2w3xXYlKTN8+7+L3f/C7CKWLIXEZEMCJPclwC9zKzIzPKAEqAioc1zwAUAZpZPbJhmXSoDFRGR8BpN7u6+BxgHvASsBJ5290ozu8fMhsWbvQRsN7MVwELgdnffnq6gRUTkwEJd5+7u84H5CWV3B7YduC3+IyIiGaY7VEVEIkjJXUQkgpTcRUQiSMldRCSClNxFRCJIyV1EJIKU3EVEIkjJXUQkgpTcRUQiSM9QFcm0aR0arivq3nJxHAQOpgfzqOcuIhJBSu4iIhGk5C4iEkFK7iIiEaTkLiISQUruIiIRpOQuIhJBSu4iIhEUKrmb2VAzW2Vma8xscpL6MWa21cyWx3+uS32oIiISVqN3qJpZLjAT+DJQDSwxswp3X5HQdI67j0tDjCIi0kRheu4DgTXuvs7ddwPlwPD0hiUiIp9HmOTeBdgQ2K+OlyW60szeNbO5ZtYtJdGJiEizhEnulqTME/Z/DRS6e39gATAr6YHMxprZUjNbunXr1qZFKiIioYVJ7tVAsCfeFdgUbODu29390/juY8AZyQ7k7qXuXuzuxQUFBc2JV0REQgiT3JcAvcysyMzygBKgItjAzDoHdocBK1MXooiINFWjV8u4+x4zGwe8BOQCT7h7pZndAyx19wrgFjMbBuwB/gGMSWPMIiLSiFAP63D3+cD8hLK7A9tTgCmpDU1ERJpLd6iKiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgEKbmLiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgEKbmLiESQkruISAQpuYuIRJCSu4hIBIV6WIeISNaY1qHhuqLuLRdHhqnnLiISQUruIiIRFCq5m9lQM1tlZmvMbPIB2o00Mzez4tSFKCIiTdVocjezXGAmcClwMjDazE5O0q49cAvwVqqDFBGRpgnTcx8IrHH3de6+GygHhidp9z3gfuCTFMYnIiLNECa5dwE2BPar42V1zOw0oJu7zzvQgcxsrJktNbOlW7dubXKwIiISTpjkbknKvK7SLAd4AJjY2IHcvdTdi929uKCgIHyUIiLSJGGSezXQLbDfFdgU2G8PnAK8amZVwCCgQpOqIiKZEya5LwF6mVmRmeUBJUBFbaW7f+Du+e5e6O6FwB+AYe6+NC0Ri4hIoxpN7u6+BxgHvASsBJ5290ozu8fMhqU7QBERabpQyw+4+3xgfkLZ3Q20HfL5wxIRkc9Dd6iKiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgE6UlM0mq0OcTofUE7DuvYBktY9ML33t7g761cuTLNkX1+jw3r3GDdSns6ocQ55IN1dF02Pb1BSaQpuUur0fuCdnTvdSztDjsCS8jue/dsafD3ju3ZK92hfW7/qt7ZYF2fnPp/q7uzfVdHqpkEWx5Jd2gSURqWkVbjsI5tkib2g42ZcfThbfikw/GZDkWymJK7tBpmHPSJvVbsfdB7Ic2n5C4iEkEac5dWa+Ajvw/Z8s+hWlXdd1no1/7Vr37FiBEjWLlyJSeddBJFRUW8+OKLnHjiiXVtbr31Vo477jjuuOMO/vjHP3LHHXewceNG2rdvT+fOnbnvvvvo169f6NcUSSX13EWSKCsr49xzz6W8vByAkpKSum2AvXv3MnfuXEaNGsWWLVu46qqr+P73v8/q1atZtmwZU6ZMYe3atZkKX0TJXSRRTU0Nb775Jj/72c/qEvro0aPrJffXX3+dwsJCevTowcMPP8y1117L2WefXVd/7rnncsUVV7R47CK1lNxFEjz33HMMHTqU3r1707FjR5YtW0b//v3JycnhnXfeAaC8vJzRo0cDUFlZyemnn57JkEX2o+QukqCsrIySkhIgNhxTVlYG7Ou979mzh+eff56vfe1rSX//rLPOok+fPnz7299usZhFEmlCVSRg+/btvPLKK7z//vuYGZ999hlmxv3338/o0aO5+OKLOf/88+nfvz+dOnUCoG/fvixbtozhw4cD8NZbbzF37lzmzZuXyT9FDnLquYsEzJ07l2uuuYb169dTVVXFhg0bKCoq4o033qBnz54cffTRTJ48uW5IBuDmm2/mySefZNGiRXVlH330USbCF6mjnru0Wn+88Yt12y21/EBZWRmTJ0+uV3bllVcye/ZsvvjFLzJ69GimTJnCV7/61X2vf+yxzJkzh0mTJrFx40Y6depEfn4+d9+d9EmUIi0iVHI3s6HAQ0Au8Li735dQ/y3gZuAzoAYY6+4rUhyrSNq9+uqr+5XdcsstddsTJkxgwoQJ+7UZNGgQr732WjpDE2mSRodlzCwXmAlcCpwMjDazkxOazXb3fu4+ALgf+FHKIxURkdDCjLkPBNa4+zp33w2UA8ODDdz9w8Du4YCnLkQREWmqMMMyXYANgf1q4KzERmZ2M3AbkAdcmOxAZjYWGAvQvXv3psYqIiIhhem5J1uabr+eubvPdPeewCRgarIDuXupuxe7e3FBQUHTIhURkdDCJPdqoFtgvyuw6QDtywHddy0ikkFhkvsSoJeZFZlZHlACVAQbmFnwWrTLgNWpC1FERJqq0TF3d99jZuOAl4hdCvmEu1ea2T3AUnevAMaZ2ZeAfwE7gGvTGbQcHDr9vFvjjZpi2gehmt17773Mnj2b3NxccnJyePTRR5k0aRKbN2/mkEMOoV27djzxxBN1y/9u3bqV4447jocffpgbbrih7jg1NTVMnDiRBQsWQJs8jjzyKCZMvYcZ35vK9eMncu4FXwbg6YqXeWLO87z41MzU/r1yUAt1nbu7zwfmJ5TdHdjWIhoSCYsXL2bevHksW7aMtm3bsm3bNnbv3g3AU089RXFxMaWlpdx+++1UVMS+wD7zzDMMGjSIsrKyesn9uuuuo6ioiNWrV/P+pg+pXl/FujWrmPr9H3H7jd/gzMFf5LO9n3Hn9Jm8+NTDGfl7Jbp0h6pIwObNm8nPz6dt27YA5Ofn79fmvPPO48EHH6zbLysrY8aMGVx99dVs3LiRLl26sHbtWt566y2eeuopcnJio59dexTStUchAOd/6RJ+/shDfPzRLq4ZeTk9C1P8LUUOelpbRiTg4osvZsOGDfTu3Zubbrop6V2nv/71r+uesLRhwwb+9re/MXDgQK666irmzJkDxJYBHjBgALm5uUlf54YJk5j/3FzeWLiAO27SKKaknpK7SEC7du14++23KS0tpaCggFGjRvHkk08C8PWvf50BAwbw5ptv8sMf/hCIret+1VVXAfWXB27MYYcdziVf+SqXXzmKtm3z0vK3yMFNwzIiCXJzcxkyZAhDhgyhX79+zJo1C9g35h5UVlbGli1beOqppwDYtGkTq1evpm/fvrzzzjvs3bu3blgmUU5ODjmm/pWkh84skYBVq1axevW+K3mXL19Ojx49Gmy7a9cuNm7cSFVVFVVVVUyZMoXy8nJ69uxJcXEx3/3ud3GP3fO3/i9rWfjS/KTHEkk19dyl1fr7N/atetFSS/7W1NQwfvx4du7cSZs2bTjhhBMoLS1l5MiR+7UtKyurt/QvxJYHLikp4a677uLxxx9n4sSJnHDCCeR8oS1HHtWRCXfek7JYRQ5EyV0k4Iwzzqj30I1ayZYCnjZt2n5l/fv3Z8WK2GrXRxxxBI899hgA71bv3K/tjbfVrhv/l2bHK9IQDcuIiESQkruISAQpuYuIRJCSu4hIBCm5i4hEkJK7iEgE6VJIabUuevWccA3fCNfsvWvfa7TNhAkT6NGjB7feeisAl1xyCd26dePxxx8HYOLEiXTp0oWJEycydepUvve97wGwbds2OnfuzA033MDDDz/MtGnTeOyxxygoKGDXrl10P+Ekxt1+Jz17nxQuWJHPST13kYCzzz677jr3vXv3sm3bNiorK+vqFy1axDnnnMPxxx/PvHnz6sqfeeYZ+vbtW+9YEyZMYPny5axevZpLvvJVri8Zzj+2b2uZP0QOekruIgHnnHNOXXKvrKzklFNOoX379uzYsYNPP/2UlStXctRRR3HooYfSp08fli5dCsCcOXPqFhBLZuiwEQw+7wJeeG5ui/wdIhqWEQk47rjjaNOmDX/9619ZtGgRgwcPZuPGjSxevJgOHTrQv39/8vJiqziWlJRQXl7OscceS25uLscddxybNjX8eOE+p5zKX9b8uaX+FDnIKbmLJKjtvS9atIjbbruNjRs3smjRIjp06MDZZ59d127o0KHcddddHHPMMYwaNarR49YuICbSEkINy5jZUDNbZWZrzGxykvrbzGyFmb1rZr8zs+TL6Ilkgdpx9/fee49TTjmFQYMGsXjx4rrx9lp5eXmcccYZzJgxgyuvvLLR4/5P5bsU9ToxnaGL1Gk0uZtZLjATuBQ4GRhtZicnNPsTUOzu/YG5wP2pDlSkpZxzzjnMmzePjh07kpubS8eOHdm5cyeLFy9m8ODB9dpOnDiR6dOnc/TRRx/wmAvmV7D49YVcOrzxfwREUiHMsMxAYI27rwMws3JgOLCitoG7Lwy0/wPw76kMUg5OvxvyZt12Sy35C9CvXz+2bdvG1VdfXa+spqaG/Px8ampq6sr79u2731UytR544AF++ctfsmvXLrr1PJHHyp+n49H7P5NVJB3CJPcuwIbAfjVw1gHa/yfwQrIKMxsLjAXo3r17yBBFWlZubi4ffvhhvbLaR+0BFBYW8v777+/3e2PGjGHMmDFAbDng4JLAyZb8FUmnMGPulqQs6cyQmf07UAz8IFm9u5e6e7G7FxcUFISPUkREmiRMz70a6BbY7wrsd72XmX0JuBM4390/TU14IiLSHGF67kuAXmZWZGZ5QAlQEWxgZqcBjwLD3P3vqQ9TRESaotHk7u57gHHAS8BK4Gl3rzSze8xsWLzZD4B2wDNmttzMKho4nIiItIBQNzG5+3xgfkLZ3YHtL6U4LhER+Ry0toyISARp+QFptbZfcqArbvfZEfJ4ff5nZah29957L7NnzyY3N5ecnBweffRRJk2axA9/+EOKi4spLCykffv25ObmAvCTn/yk3rIEIq2BkrtIwOLFi5k3bx7Lli2jbdu2bNu2jd27d+/XbuHCheTn64Ykab2U3EUCNm/eTH5+Pm3btgVQApespTF3kYCLL76YDRs20Lt3b2666SZee+21pO0uuOACBgwYwFlnhRs6Emlp6rmLBLRr1463336b3//+9yxcuJBRo0Zx33337ddOwzLS2im5iyTIzc1lyJAhDBkyhH79+jFr1qxMhyTSZBqWEQlYtWoVq1evrttfvnw5PXro8QSSfdRzl1br6JfeqttuqSV/a2pqGD9+PDt37qRNmzaccMIJlJaWMnLkyJS9hkhLUHIXCTjjjDPqHpAd9Oqrr9ZtV1VVtVxAIs2kYRkRkQhSchcRiSAldxGRCFJyFxGJICV3EZEIUnIXEYkgXQoprdYz/7U0ZMsNoVrd/NMLQ7XbsmULEyZM4A9/+ANHHXUUeXl53HHHHVxyySVcf/31vPvuu7g7Rx55JC+++CLt2rUjNzeXfv361R2jpKSEyZMnh4xfJPWU3EUC3J0rrriCa6+9ltmzZwOwfv16KioqeOihhzjmmGN47733gNjdrF/4whcAOPTQQ1m+fHnG4hZJpGEZkYBXXnmFvLw8vvWtb9WV9ejRg/Hjx7N582a6dOlSV37iiSfWLQ0s0tqESu5mNtTMVpnZGjPb77ummZ1nZsvMbI+Z6T5tyVqVlZWcfvrpSeu++c1vMn36dAYPHszUqVPrrUHz8ccfM2DAgLqfOXPmtFTIIkk1OixjZrnATODLQDWwxMwq3H1FoNlfgTHA/0pHkCKZcvPNN/PGG2+Ql5fHkiVLWLduHS+//DILFizgzDPPZPHixfTp00fDMtLqhBlzHwiscfd1AGZWDgwH6pK7u1fF6/amIUaRFtO3b1+effbZuv2ZM2eybds2iouLgdh67yNGjGDEiBHk5OQwf/58+vTpk6lwRRoUZlimC/UvR6iOlzWZmY01s6VmtnTr1q3NOYRIWl144YV88sknPPLII3VlH330EQBvvvkmO3bEHse9e/duVqxYoeWApdUK03O3JGXenBdz91KgFKC4uLhZx5CDx9emFNdtt9SSv2bGc889x4QJE7j//vspKCjg8MMPZ/r06axdu5Ybb7wRd2fv3r1cdtllXHnllcC+MfdaQ4cOTfoEJ5GWEia5VwPdAvtdgU3pCUck8zp37kx5eXnSumuuuSZp+WeffZbOkESaLMywzBKgl5kVmVkeUAJUpDcsERH5PBpN7u6+BxgHvASsBJ5290ozu8fMhgGY2ZlmVg18DXjUzCrTGbSIiBxYqDtU3X0+MD+h7O7A9hJiwzUiItIK6A5VEZEIUnIXEYkgJXcRkQjSqpDSav3ijqtTeryJc+Y12qZdu3bU1NRQVVVFUVERP/7xjxk/fjwA48aNo7i4mDFjxjBmzBhee+01OnToAMTWnbnllltSGq/I56HkLtKATp068dBDD3HDDTeQl5e3X/0PfvADRo7UOnnSOmlYRqQBBQUFXHTRRcyaNSvToYg0mZK7yAFMnjyZGTNmJL0D9fbbb69b4rf2AR4irYWGZUQOoKioiIEDB9Y9lSlIwzLSmqnnLtKI73znO0yfPp29e7WitWQPJXeRRpx00kmcfPLJzJvX+NU2Iq2FhmWk1fqP+/cNhbTUkr8NufPOOznttNPS/joiqaLkLhJQU1MDQGFhIe+//35d+amnnlpvWObJJ59s6dBEmkTDMiIiEaTkLiISQUru0mq4g7uevgi174PeC2k+JXdpNT76xx5qPvrwoE/w7s72XXs45IN1mQ5FspgmVKXV+PPCGuBvHNZxG5bwWHbf+2GDv7dj9570BpYCW3Z83GDdStuaUOIc8sE6ui6bDl2OSG9gEllK7tJq7PnEWfHCP5PWfbLjRw3+XpjVHjPt0sm/abCu6pADrX6p5C7NE2pYxsyGmtkqM1tjZpOT1Lc1sznx+rfMrDDVgYqISHiNJnczywVmApcCJwOjzezkhGb/Cexw9xOAB4DpqQ5URETCC9NzHwiscfd17r4bKAeGJ7QZDtSuizoXuMgscdRURERaijV2ZYKZjQSGuvt18f3/AM5y93GBNu/H21TH99fG22xLONZYYGx890RgVar+kDTKB7Y12krC0vuZOnovUytb3s8e7l7QWKMwE6rJeuCJ/yKEaYO7lwKlIV6z1TCzpe5enOk4okLvZ+rovUytqL2fYYZlqoFugf2uwKaG2phZG6AD8I9UBCgiIk0XJrkvAXqZWZGZ5QElQEVCmwrg2vj2SOAVP9jvRBERyaBGh2XcfY+ZjQNeAnKBJ9y90szuAZa6ewXwM+AXZraGWI+9JJ1Bt7CsGkbKAno/U0fvZWpF6v1sdEJVRESyj9aWERGJICV3EZEIUnIXEYkgJXcRkQhScg8ws+fMbJSZHZrpWLKdmX0v0zFEiZn9xsy+bmaHZzqWKDCz72c6hnRTcq/vF8Su019vZk+Z2eXxm7Kk6S7LdAARUwpcDvwlvgLrFfH7TqR5hmY6gHTTpZBJxHtHVxC7Xr8Y+DVQ5u4LMxpYFjGzd4BzSb40Be7e8NM3pEHxb5XDiJ2bg4H5xM7N32Y0sCwTPz+H0PD5mfV32Cu5N8LM+gH/DfR399xMx5MtzOxTYAv1Pzwe33d3756RwCLEzPoTW41V52YTxc/PjTSwLpa7H9/CIaWchhySMLN84GvEekeFxJYxvj6TMWWhFe5+WqaDiBozOwa4iti52Rl4BvhGRoPKTpE/P5XcA8zsG8BooB/wHHA38LrWyZFMiy+XXUJsqez/B9zh7m9mNippzZTc67sQeBB42d1b/1OXW7eHEwvMrL27J39IqjRmMHAfsMDd92Y6mAh4KLHAzI4CdkalM6erZeqb7+7z44ulDQpWmNmNmQoqSx1rZicBmFmemf0WqDazLWZ2YYZjy0a/c/eX3X2vmZ0TrIgv7CdN0z1wfrY1s4XAWmCLmX0ps6GlhpJ7fbcHtn+SUKcx96a5mn1P2roGyAOOJvbt6L8yFVQWuy2w/X8T6r7ZkoFExCj2nZ+1y5UXAOcDkbgGXsm9PmtgO9m+HNjuwNfbocQu19vj7pXAFzIYV7bSuZlawfPzEqDc3T9z95VEZLhayb0+b2A72b4c2Kdm1sfManvrLwfqDstQTNlM52ZqfWpmp5hZAXABETw/I/EvVAqdZGbLiPWEToxvE9/vnbmwstJEYk/oygcecvd1AGb2b8C7mQwsS51kZu8SOxd7xreJ72f9NdkZcCuxS5wLgAfc/S9Qd37+KZOBpYpuYgows54Hqnf3tS0Vi0iQmfU4UL27r2+pWCQ7aFgmwN3XxhP434Ej4j9bAuUSkpnNCGyPS6j7WctHlN3cfX08gX8AdIr/7AyUSxOY2YOB7W8n1D3Z4gGlgZJ7QPySvceJ3ZY8i9hCYtVmVmpmmgRsmgsC24lXc0T6zsB0iJ+bTwJVxBYRewyoMrMntIBYs5wX2L42oa5/SwaSLkru9d0JtAO6unt/dz8F6AEcDkzNaGTZ50BXd0jTTSV2lVE3dz/N3QcA3YnNm92V0ciyU+TPTyX3+kYA1wVXLHT3D4BvxeskvBwza29mHQLbR5jZEYAWuWq6EcD1wTt849s3AV/NWFTZK8fMjopfzVW73dHMOhKR81NXyyRw95okZf80M808N83RQCX7ekUrCKwKmamgsthed/8osdDda3RuNksH4G32nZ/LAnWReD+V3Ovba2btaWAZ0JYOJssNcvfqTAcRIR5f+yTZuam1Zpru/KhPROtSyAAzqyb2QWlojWetQR6SmS1z99MzHUdUmFkVBz43da17ExwM56d67gHu3jXTMURIJCepMsXdCzMdQ8RE/vxUz70RZjbV3f9PpuPINmb2d+CXDdW7+20N1Uk4ZjbN3adlOo5sFD8/yxuqd/dbWjCctFDPvXEjACX3pvuY2ISqpM8wYFqmg8hSHxObUI0sJffGRf7rW5psd3fdiZpeOjebb7u7z8p0EOmk69wDzCzZmPvAeN1XWjicbPdZpgM4CER6QjDNdmc6gHRTcq/vd2ZWGCxw93+Z2TeJPX5PQnL3MxPLzEx3+TaTmV1vZr3i22ZmPwd2mtm7ZqYk30TuPiixzMymZSCUtFFyr28C8NvaDxGAmU2Jl5+fsaiiQ3f5Nt+3ia0rA7GHuPcnttTvbSR5Hqg0y7BMB5BKSu4B7j6f2FIDL8QX8n8QuBw4TzfkpITGiJtvj7v/K759OfDf7r7d3RcQW/tIPr9InZ9K7gnc/XfAGOBVYj2ji9x9RyZjykaav0i5vWbW2cwOAS4CFgTqDs1QTFETqeEtJfcAM/unmX0IvEBsLfeLgL8HyiU8zV+k1l3AUmJDMxXxZ9FiZucD6zIYV1Y6GOYwdClkgLu3z3QMEVI7f/Fv7r4a6uYvrkbzF82xndjy0+0TvkkuBUZlJqSs9m3gyfh2cA7jNGJzGF/MTFipo557gJmdaWaXJin/ipmdkYmYspXmL1LuJ+6+J3GI0N13JVvJVBoV+TkMJff6fgCsTFK+Ml4nTaD5C2nFIj+HoWGZ+o5hc7veAAACfklEQVR296rEQndfE1/UX0Iys3+yb/32tuybvzBiqxgekcn4stDxZlbRUKW7R+oyvhZQO4eRS0TnMJTc6zvQv9iR+KrWUjR/kXJbgRmNtpKwIj+HoVUhA8zsp8T+p0/1wBtjZv8b6OzuYzMWXJYxszOBfHd/IaH8K8Amd4/0ok2pZmZ/cnc9WDxFDob13DXmXt9EYmPDa8zs2fjPGuBEYncCSniav0itHWZ2bO2OmV1jZs+b2Y/jz/0UqUc99yTM7Higb3y30t0jMQbXkszsPXfv10DdO+5+akvHlM3MbBnwJXf/h5mdR2wt8vHAAKCPu4/MaIBZxsx2Aq83VB+FOQyNuQck3LywMf7fI2vL3X3Z/r8lDdD8RWrluPs/4tujgFJ3fxZ41syWZzCubBX5OQwl9/oS/2cnfq25sKUCiYAFZnYvyecvXslcWFmrjZm1cfc9xK48Cs7/6HPcdDXu/lqmg0gnnRT1TQI2uPtmADO7FriS2C3f0zIXVlaaCDxObP6itmd5KrGrEa7LWFTZqwx4zcy2EXuK0O8BzOwE4INMBpaldpjZse7+N4jNYRD7rK8HpgW+JWUtjbkHaFwz9TR/kTpmNgjoDLzs7rviZb2BdhoybJqD4bOu5B4QnOgzs5nA1toHEJvZcncfkMn4skljiy8pGUkmBT/PUf2sa1imvlyNa6aM5i+kNYv8HEYk/ogU0rhm6mj+QlqzyH/WNSyTQOOaqXEwjGlKdov6Z13JXdJC8xcimaXlByRdcs2sdtjvIupf267hQJE004dM0iXyY5oirZmGZSRtoj6mKdKaKbmLiESQxtxFRCJIyV1EJIKU3EVEIkjJXUQkgv4/XV3KEOzMPXkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x30c34fdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.transpose()\n",
    "results_df = results_df.rename(columns={i:method[0] for i, method in enumerate(benchmarks)})\n",
    "\n",
    "results_df.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
