{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with a CNN in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"data/text_classification/20newsgroups_train.tsv\"\n",
    "DEV_PATH = \"data/text_classification/20newsgroups_dev.tsv\"\n",
    "TEST_PATH = \"data/text_classification/20newsgroups_test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train = fetch_20newsgroups(subset=\"train\")\n",
    "target_names = train.target_names\n",
    "label2idx = {label: idx for idx, label in enumerate(target_names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the English spacy model installed, as this will be used for tokenization:\n",
    "    \n",
    "```\n",
    "> pip install spacy\n",
    "> python -m spacy download en\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "from torchtext.data import TabularDataset, Field, BucketIterator\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "text = Field(sequential=True, tokenize=\"spacy\")\n",
    "label = Field(sequential=False, use_vocab=False, preprocessing=lambda x: label2idx[x])\n",
    "\n",
    "train_data = TabularDataset(path=TRAIN_PATH, format='tsv', fields=[('label', label), ('text', text)])\n",
    "dev_data = TabularDataset(path=DEV_PATH, format='tsv', fields=[('label', label), ('text', text)])\n",
    "test_data = TabularDataset(path=TEST_PATH, format='tsv', fields=[('label', label), ('text', text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "\n",
    "text.build_vocab(train_data, max_size=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_iter = BucketIterator(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_iter = BucketIterator(dataset=dev_data, batch_size=BATCH_SIZE)\n",
    "test_iter = BucketIterator(dataset=test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, filter_sizes, num_filters, vocab_size, output_size):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        # 1. Embedding Layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 2. LSTM Layer\n",
    "        self.cnn = nn.ModuleList([nn.Conv1d(1, num_filters, (fs, embedding_dim)) for fs in filter_sizes])\n",
    "\n",
    "        # 3. Dense Layer\n",
    "        self.hidden2out = nn.Linear(num_filters*len(filter_sizes), output_size)\n",
    "        \n",
    "        # Optional dropout layer\n",
    "        self.dropout_layer = nn.Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, batch_text):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "\n",
    "        embeddings = embeddings.transpose(0,1)  # (batch, length, embed_dim)\n",
    "        embeddings = embeddings.unsqueeze(1)    # (batch, channels, length, embed_dim)\n",
    "        conv_out = [conv(embeddings) for conv in self.cnn]  # (batch, num_filters, output_length, 1)\n",
    "        conv_out = [F.relu(t).squeeze(3) for t in conv_out]\n",
    "        conv_out = [F.max_pool1d(t, t.size(2)).squeeze(2) for t in conv_out]\n",
    "        conv_out = torch.cat(conv_out, 1)\n",
    "\n",
    "        conv_out = self.dropout_layer(conv_out)\n",
    "        final_output = self.hidden2out(conv_out)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train(model, train_iter, dev_iter, batch_size, num_batches):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    max_epochs = 20\n",
    "    loss_history = []\n",
    "    patience = 2\n",
    "    best_state_path = None\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in tqdm(train_iter, total=num_batches):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(batch.text.to(device))\n",
    "            loss = criterion(pred, batch.label.to(device))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predictions += list(pred_indices.cpu().numpy())\n",
    "            correct += list(batch.label.cpu().numpy())\n",
    "\n",
    "        print(\"=== Epoch\", epoch, \"===\")\n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training performance:\", precision_recall_fscore_support(correct, predictions, average=\"micro\"))\n",
    "        \n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        for batch in dev_iter:\n",
    "\n",
    "            pred = model(batch.text.to(device))\n",
    "            loss = criterion(pred, batch.label.to(device))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            pred_indices = list(pred_indices.cpu().numpy())\n",
    "            predictions += pred_indices\n",
    "            correct += list(batch.label.cpu().numpy())\n",
    "\n",
    "        print(\"Total development loss:\", total_loss)\n",
    "        dev_stats = precision_recall_fscore_support(correct, predictions, average=\"micro\")\n",
    "        print(\"Development performance:\", dev_stats)\n",
    "        \n",
    "        if len(loss_history) == 0 or total_loss < min(loss_history): \n",
    "            fscore = dev_stats[2]\n",
    "            path = f\"model_state_{epoch}_{round(total_loss,2)}_{round(fscore,2)}\"\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_state_path = path\n",
    "            \n",
    "        if len(loss_history) > 0 and total_loss > max(loss_history[-patience:]):\n",
    "            print(\"No improvement on development set. Finishing training.\")\n",
    "            break\n",
    "            \n",
    "        loss_history.append(total_loss)\n",
    "        \n",
    "    return best_state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eef0c3616f040789a11cd3214245629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=707), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 0 ===\n",
      "Total training loss: 1744.2471042275429\n",
      "Training performance: (0.31474279653526605, 0.31474279653526605, 0.31474279653526605, None)\n",
      "Total development loss: 1002.7418279647827\n",
      "Development performance: (0.3990971853425385, 0.3990971853425385, 0.3990971853425385, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460b0f6249114c269dc12deb74b671bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=707), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1 ===\n",
      "Total training loss: 807.0345216393471\n",
      "Training performance: (0.6590065405692063, 0.6590065405692063, 0.6590065405692063, None)\n",
      "Total development loss: 741.3295960128307\n",
      "Development performance: (0.5536378120021243, 0.5536378120021243, 0.5536378120021243, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb66b9927ac6427f8877ea16c11d5b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=707), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 2 ===\n",
      "Total training loss: 404.7720814496279\n",
      "Training performance: (0.8332154852395263, 0.8332154852395263, 0.8332154852395263, None)\n",
      "Total development loss: 623.7967542409897\n",
      "Development performance: (0.6317047265002655, 0.6317047265002655, 0.6317047265002655, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6bd22f555a483db80730f8799c9960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=707), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 3 ===\n",
      "Total training loss: 214.2018345296383\n",
      "Training performance: (0.9164751635142302, 0.9164751635142302, 0.9164751635142302, None)\n",
      "Total development loss: 648.8073130249977\n",
      "Development performance: (0.6509559214020181, 0.6509559214020181, 0.6509559214020181, None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4884f700869f4a88a0c4ae765ed0f21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=707), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 4 ===\n",
      "Total training loss: 137.84940619766712\n",
      "Training performance: (0.9481173767014318, 0.9481173767014318, 0.9481173767014319, None)\n",
      "Total development loss: 665.8534139245749\n",
      "Development performance: (0.658656399362719, 0.658656399362719, 0.658656399362719, None)\n",
      "No improvement on development set. Finishing training.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "NUM_FILTERS = 128\n",
    "FILTER_SIZES = [3,4,5]\n",
    "NUM_CLASSES = len(label2idx)\n",
    "num_batches = int(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "classifier = CNNClassifier(EMBEDDING_DIM, FILTER_SIZES, NUM_FILTERS, VOCAB_SIZE+2, NUM_CLASSES)  \n",
    "\n",
    "best_state_path = train(classifier.to(device), train_iter, dev_iter, BATCH_SIZE, num_batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def test(model, state_path, test_iter, batch_size, num_batches, target_names):\n",
    "    \n",
    "    model.load_state_dict(torch.load(state_path))\n",
    "    \n",
    "    predictions, correct = [], []\n",
    "    for batch in test_iter:\n",
    "\n",
    "        pred = model(batch.text.to(device))\n",
    "        _, pred_indices = torch.max(pred, 1)\n",
    "\n",
    "        pred_indices = list(pred_indices.cpu().numpy())\n",
    "        predictions += pred_indices\n",
    "        correct += list(batch.label.cpu().numpy())\n",
    "\n",
    "    print(classification_report(correct, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.55      0.63      0.58       319\n",
      "           comp.graphics       0.58      0.38      0.46       389\n",
      " comp.os.ms-windows.misc       0.56      0.67      0.61       394\n",
      "comp.sys.ibm.pc.hardware       0.51      0.47      0.49       392\n",
      "   comp.sys.mac.hardware       0.59      0.65      0.62       385\n",
      "          comp.windows.x       0.67      0.69      0.68       395\n",
      "            misc.forsale       0.76      0.71      0.73       390\n",
      "               rec.autos       0.75      0.63      0.68       396\n",
      "         rec.motorcycles       0.75      0.83      0.79       398\n",
      "      rec.sport.baseball       0.70      0.60      0.65       397\n",
      "        rec.sport.hockey       0.74      0.81      0.78       399\n",
      "               sci.crypt       0.84      0.72      0.78       396\n",
      "         sci.electronics       0.34      0.48      0.40       393\n",
      "                 sci.med       0.56      0.56      0.56       396\n",
      "               sci.space       0.82      0.62      0.71       394\n",
      "  soc.religion.christian       0.70      0.72      0.71       398\n",
      "      talk.politics.guns       0.60      0.66      0.63       364\n",
      "   talk.politics.mideast       0.81      0.66      0.73       376\n",
      "      talk.politics.misc       0.43      0.59      0.50       310\n",
      "      talk.religion.misc       0.52      0.42      0.47       251\n",
      "\n",
      "             avg / total       0.64      0.63      0.63      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STATE_PATH = best_state_path\n",
    "num_batches = int(len(test_data) / BATCH_SIZE)\n",
    "\n",
    "classifier = CNNClassifier(EMBEDDING_DIM, FILTER_SIZES, NUM_FILTERS, VOCAB_SIZE+2, NUM_CLASSES)  \n",
    "\n",
    "test(classifier.to(device), STATE_PATH, test_iter, BATCH_SIZE, num_batches, target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
